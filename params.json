{"name":"3D-MTM for Gesture Recognition","tagline":"This code is developed for the work \"Three Dimensional Motion Trail Model for Gesture Recognition\"","body":"Three Dimensional Motion Trail Model for Gesture Recognition.\r\n \r\nThis code is developed for the work: **Bin Liang, Lihong Zheng \"Three Dimensional Motion Trail Model for Gesture Recognition,\"  ICCV 2013 Workshop - Big Data in 3D Computer Vision Workshop.**\r\n\r\n_In case of publication with this code, please cite the paper above._\r\n\r\nDataset: [MSR Action3D Dataset](http://research.microsoft.com/en-us/um/people/zliu/actionrecorsrc/MSR-Action3D.zip)\r\n\r\nHOW to use:\r\n\r\n1. Two SVM files can be generated after running the program, namely \"TR_Gestures.svm\" and \"TE_Gestures.svm\";\r\n\r\n2. \"TR_Gestures.svm\" and \"TE_Gestures.svm\" are used as inputs for LIBSVM. The commands are:\r\n\r\n    a.  ## data scale\r\n        svm-scale.exe -l -1 -u 1 -s t_range TR_Gestures.svm > TR_Gestures.svm.scale \r\n        svm-scale.exe -r t_range TE_Gestures.svm > TE_Gestures.svm.scale\r\n\r\n    b.  ## find out the best C and gamma for the SVM model\r\n        python.exe grid.py TR_Gestures.svm.scale\r\n\r\n    c.  ## train model\r\n        svm-train.exe -c [best C] -g [bset gamma] TR_Gestures.svm.scale\r\n\r\n    d.  ## predict using trained model\r\n        svm-predict.exe TE_Gestures.svm.scale TR_Gestures.svm.scale.model TE_Gestures.svm.predict\r\n","google":"UA-45888636-1","note":"Don't delete this file! It's used internally to help with page regeneration."}