<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print" />

    <title>3D-MTM for Gesture Recognition by 1987hasit</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1>3D-MTM for Gesture Recognition</h1>
        <h2>This code is developed for the work &quot;Three Dimensional Motion Trail Model for Gesture Recognition&quot;</h2>

        <section id="downloads">
          <a href="https://github.com/1987hasit/MSR-Aciton3D-v1/zipball/master" class="btn">Download as .zip</a>
          <a href="https://github.com/1987hasit/MSR-Aciton3D-v1/tarball/master" class="btn">Download as .tar.gz</a>
          <a href="https://github.com/1987hasit/MSR-Aciton3D-v1" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">
        <p>Three Dimensional Motion Trail Model for Gesture Recognition.</p>

<p>This code is developed for the work: Bin Liang, Lihong Zheng "Three Dimensional Motion Trail Model for Gesture Recognition," 
ICCV 2013 Workshop - Big Data in 3D Computer Vision Workshop.</p>

<p>In case of publication with this code, please cite the paper above.</p>

<p>Dataset: MSR Action3D dataset</p>

<p>HOW to use:</p>

<p>(1) Two SVM files can be generated after running the program, namely "TR_Gestures.svm" and "TE_Gestures.svm";</p>

<p>(2) "TR_Gestures.svm" and "TE_Gestures.svm" are used as inputs for LIBSVM. The commands are:</p>

<pre><code>a.  ## data scale
    svm-scale.exe -l -1 -u 1 -s t_range TR_Gestures.svm &gt; TR_Gestures.svm.scale 
    svm-scale.exe -r t_range TE_Gestures.svm &gt; TE_Gestures.svm.scale

b.  ## find out the best C and gamma for the SVM model
    python.exe grid.py TR_Gestures.svm.scale

c.  ## train model
    svm-train.exe -c [best C] -g [bset gamma] TR_Gestures.svm.scale

d.  ## predict using trained model
    svm-predict.exe TE_Gestures.svm.scale TR_Gestures.svm.scale.model TE_Gestures.svm.predict
</code></pre>
      </section>
    </div>

              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-45888636-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>