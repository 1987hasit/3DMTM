<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="3D-MTM for Gesture Recognition : This code is developed for the work &quot;Three Dimensional Motion Trail Model for Gesture Recognition&quot;" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>3D-MTM for Gesture Recognition</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/1987hasit/MSR-Aciton3D-v1">View on GitHub</a>

          <h1 id="project_title">3D-MTM for Gesture Recognition</h1>
          <h2 id="project_tagline">This code is developed for the work &quot;Three Dimensional Motion Trail Model for Gesture Recognition&quot;</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/1987hasit/MSR-Aciton3D-v1/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/1987hasit/MSR-Aciton3D-v1/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p>Three Dimensional Motion Trail Model for Gesture Recognition.</p>

<p>This code is developed for the work: Bin Liang, Lihong Zheng "Three Dimensional Motion Trail Model for Gesture Recognition," ICCV 2013 Workshop - Big Data in 3D Computer Vision Workshop.</p>

<p>In case of publication with this code, please cite the paper above.</p>

<p>Dataset: MSR Action3D dataset</p>

<p>HOW to use:</p>

<p>(1) Two SVM files can be generated after running the program, namely "TR_Gestures.svm" and "TE_Gestures.svm";
(2) "TR_Gestures.svm" and "TE_Gestures.svm" are used as inputs for LIBSVM. The commands are:
    a.  ## data scale
        svm-scale.exe -l -1 -u 1 -s t_range TR_Gestures.svm &gt; TR_Gestures.svm.scale
        svm-scale.exe -r t_range TE_Gestures.svm &gt; TE_Gestures.svm.scale
    b.  ## find out the best C and gamma for the SVM model
        python.exe grid.py TR_Gestures.svm.scale
    c.  ## train model
        svm-train.exe -c [best C] -g [bset gamma] TR_Gestures.svm.scale
    d.  ## predict using trained model
        svm-predict.exe TE_Gestures.svm.scale TR_Gestures.svm.scale.model TE_Gestures.svm.predict</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">3D-MTM for Gesture Recognition maintained by <a href="https://github.com/1987hasit">1987hasit</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
